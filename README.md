# ğŸ¤– MACHINE-LEARNING-TASK  
### ğŸ§© Two End-to-End Machine Learning Projects: Manufacturing Efficiency & Retail Web Session Intelligence  

---

## ğŸ—‚ï¸ Repository Structure
```
MACHINE-LEARNING-TASK/
â”‚
â”œâ”€â”€ task1/
â”‚ â”œâ”€â”€ manufacturing.ipynb
â”‚ â””â”€â”€ manufacturing_data(in).csv
â”‚
â””â”€â”€ task2/
â”œâ”€â”€ rwsi.ipynb
â””â”€â”€ rwsi_data(in).csv
```


Each task is an independent ML project covering complete stages â€” from **data preprocessing** to **model building**, **evaluation**, and **visualization**.

---

# ğŸ­ Task 1: Manufacturing Efficiency Analysis & Prediction  

---

## ğŸš€ Overview
This task predicts **manufacturing team efficiency** using workforce and production parameters.  
It explores how factors like **idle time**, **overtime**, **bonuses**, and **planned efficiency** influence the overall **performance score**.

---

## ğŸ§© Dataset Summary
- **File:** `manufacturing_data(in).csv`
- **Goal:** Predict team `efficiencyScore`
- **Records:** Several hundred production logs
- **Features:**  
  - ğŸ§® **Numerical:** workerCount, idleMinutes, overtimeMinutes, performanceBonus, plannedEfficiency  
  - ğŸ·ï¸ **Categorical:** department, styleChangeCount  

---

## ğŸ” Exploratory Data Analysis (EDA)

### Univariate Analysis
- Most numeric features show **right skewness** (e.g., `idleMinutes`, `performanceBonus`).
- Outliers detected and treated using **IQR**.
- **Categorical Insights:**  
  - Certain departments maintain consistently higher efficiency.  
  - Higher **style changes** reduce performance slightly.  

### Bivariate Analysis
- **High Efficiency:** Low idle time, high planned efficiency, good bonuses.  
- **Negative correlation:** `idleMinutes` vs `efficiencyScore`.  
- **Positive correlation:** `plannedEfficiency` vs `efficiencyScore`.

---

## ğŸ§¹ Data Preprocessing
- **Missing Values:** Median (numerical), Mode (categorical)  
- **Outliers:** IQR capping and median replacement  
- **Encoding:** Label Encoding for categorical variables  
- **Scaling:** MinMaxScaler  
- **Data Split:** 80% Train | 20% Test  

---

## âš™ï¸ Model Building
Three regression models implemented:

| Model | Purpose |
|--------|----------|
| Linear Regression | Baseline model |
| Decision Tree Regressor | Handles nonlinear relationships |
| Random Forest Regressor | Ensemble model for best accuracy |

---

## ğŸ“Š Evaluation Metrics
| Metric | Description |
|--------|-------------|
| RÂ² Score | Measures goodness of fit |
| MAE | Mean Absolute Error |
| RMSE | Root Mean Squared Error |

---

## ğŸ§  Model Comparison
| Model | RÂ² Score | RMSE | Observation |
|--------|-----------|------|-------------|
| Linear Regression | ~0.72 | Moderate | Simple baseline |
| Decision Tree | ~0.80 | Lower | Captures nonlinearity |
| Random Forest | **~0.88** | **Lowest** | Best generalization |

âœ… **Random Forest** achieved the best results with stable performance.

---

## ğŸ“ˆ Visualization Highlights
- **Heatmap:** Correlations among numeric features  
- **Boxplots:** Outlier detection  
- **Scatterplots:** Planned vs Actual efficiency  
- **Feature Importance:** plannedEfficiency, bonus, idleMinutes  

---

## ğŸ’¡ Key Insights
- Planned efficiency & performance bonus are major productivity drivers.  
- Idle time negatively impacts output.  
- Balanced overtime enhances short-term results.  

---

## ğŸ”® Future Enhancements
- Apply **XGBoost / LightGBM**  
- **Hyperparameter tuning**  
- Deploy model via **Streamlit Dashboard**  
- Integrate **Explainable AI (SHAP, LIME)**  

---

## ğŸ§° Tech Stack
Python | pandas | numpy | matplotlib | seaborn | scikit-learn | Jupyter Notebook  

---

## ğŸ Conclusion
A complete ML pipeline predicting **factory team efficiency**, providing actionable insights for better workforce and production management.

---

# ğŸ§  Task 2: Retail Web Session Intelligence (RWSI) â€” Conversion Prediction  

---

## ğŸš€ Overview
This project analyzes customer web sessions to **predict purchase conversions** on a retail platform.  
It leverages behavioral and contextual session data to support data-driven marketing strategies.

---

## ğŸ§© Dataset Summary
- **File:** `rwsi_data(in).csv`
- **Goal:** Predict `MonetaryConversion` (Yes/No)
- **Records:** Thousands of web sessions
- **Features:**  
  - ğŸ§® **Numerical:** engagement metrics, browsing time, item views  
  - ğŸ·ï¸ **Categorical:** platform, region, user type, month, weekday flag  

---

## ğŸ” Exploratory Data Analysis (EDA)

### Univariate Analysis
- Right-skewed distributions (`ItemBrowseTime`, `EngagementScore`).
- Outliers addressed later using IQR.
- **Categorical Highlights:**
  - `VisitMonth`: Peaks in **March, May, November, December**
  - `UserPlatformID`: Dominated by **Android & iOS**
  - `MarketZone`: Highest conversions in **North America, Asia-Pacific**

### Bivariate Analysis
- Higher conversion likelihood among:
  - **Returning mobile users**
  - **Festive months**
  - **North America** region
- Engagement metrics correlate strongly with conversions.

---

## ğŸ§¹ Data Preprocessing
- **Missing Values:** Median / Mode imputation  
- **Outlier Treatment:** IQR method  
- **Skewness Fix:** PowerTransformer (Yeo-Johnson)  
- **Encoding:** Label encoding for target; One-hot for features  
- **Scaling:** MinMaxScaler  
- **Data Split:** 80% Train | 20% Test  

---

## âš™ï¸ Model Building
Classification models implemented to predict conversion outcomes.

| Model | Description |
|--------|-------------|
| Logistic Regression | Interpretable baseline |
| Decision Tree | Handles nonlinearity |
| Random Forest | Ensemble method for accuracy & robustness |

---

## ğŸ“Š Evaluation Metrics
| Metric | Description |
|--------|-------------|
| Accuracy | Correct predictions |
| Precision | Positive prediction accuracy |
| Recall | Sensitivity to conversions |
| F1-Score | Balance between precision and recall |
| ROC-AUC | Class separation measure |

---

## ğŸ§  Model Comparison
| Model | Accuracy | ROC-AUC | Observation |
|--------|-----------|----------|--------------|
| Logistic Regression | ~0.78 | ~0.80 | Good baseline |
| Decision Tree | ~0.83 | ~0.85 | Nonlinear capture |
| Random Forest | **~0.88** | **~0.90** | Best performer |

âœ… **Random Forest Classifier** delivered the highest accuracy and generalization.

---

## ğŸ“ˆ Visualization Highlights
- **Correlation Heatmap:** Feature interdependence  
- **Bar Plots:** Conversion trends per category  
- **ROC Curve:** Model comparison  
- **Feature Importance:** engagementScore, ItemBrowseTime, UserPlatformID  

---

## ğŸ’¡ Key Insights
- **Returning mobile users** have higher conversion rates.  
- **Engagement behavior** is the strongest predictor.  
- **Festive months** correlate with higher conversions.  

---

## ğŸ”® Future Enhancements
- Hyperparameter tuning (GridSearchCV / RandomizedSearchCV)  
- Try **Gradient Boosting (XGBoost / LightGBM)**  
- Feature selection with **SHAP / Permutation Importance**  
- Deployment via **Flask / Streamlit**  

---

## ğŸ§° Tech Stack
Python | pandas | numpy | scikit-learn | matplotlib | seaborn | Jupyter Notebook  

---

## ğŸ Conclusion
An end-to-end ML system for predicting **customer conversion likelihood**, enabling better targeting and business optimization.

---

# âš™ï¸ Combined Overview

| Task | Type | Model | Best Accuracy / RÂ² | Key Insight |
|------|------|--------|--------------------|--------------|
| ğŸ­ Manufacturing | Regression | Random Forest | RÂ² â‰ˆ 0.88 | Efficiency depends on planned output & idle time |
| ğŸ§  Retail Web Session | Classification | Random Forest | Accuracy â‰ˆ 0.88 | Conversions depend on engagement & platform behavior |

---

## â­ How to Use
1. Clone the repository  
   ```bash
   git clone https://github.com/<your-username>/MACHINE-LEARNING-TASK.git

2. Navigate to the desired task

   ```bash
   cd MACHINE-LEARNING-TASK/task1   # or task2
   ```
3. Open the Jupyter Notebook

   ```bash
   jupyter notebook manufacturing.ipynb
   ```
4. Run all cells to reproduce results.

---

## ğŸ† Final Note

Both projects demonstrate complete **Machine Learning lifecycles** â€”
from **raw data to model interpretation**, producing reliable predictions and insights
for **real-world decision-making** across **industrial** and **retail** domains.
